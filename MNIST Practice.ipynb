{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is practice for ML on MNIST digits taken from https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical #convert to one-hot encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"], axis = 1) \n",
    "# Free some space\n",
    "del train\n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This checked for corrupt images (missing values inside). Looks like there are no missing values in the train and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform grayscale normalization to reduce the effect of illumination's differences.\n",
    "\n",
    "Also, the CNN converges faster on [0,1] data than on [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image in 3 dimensions (height = 28px, width = 28px, depth = 1)\n",
    "\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "test = test.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test images we received were pandas.Dataframe as 1D vectors of length 784.  We reshape all of it into 28x28x1 matrices.\n",
    "\n",
    "If we were using colors, as in RGC, we would use 28x28x3 matrices.\n",
    "\n",
    "These are known as channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex: 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are 10 digit numbers from 0 to 9. We need to encode these labels as one hot vectors (ex: 2 -> [0,0,1,0,0,0,0,0,0,0])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, \n",
    "                                                  random_state = random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the train set into 10% validation and 90% to train the model.\n",
    "\n",
    "Since we have 42,000 training images of balanced labels, a random split of the train set doesn't cause some of the labels to be over represented in the validation set.  This can be an issue if the dataset is unbalanced, since a simple random split could cause inaccurate evaluation during the validation.\n",
    "\n",
    "To avoid this in that case, use stratify = True option in train_test_split function (only for >= 0.17 sklearn versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some examples\n",
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN (Convolutional Neural Network)\n",
    "\n",
    "Defining the model.\n",
    "\n",
    "This user used Keras Sequential API, where you have just to add one layer at a time, starting from the input.\n",
    "\n",
    "The first convolutional layer : Conv2D;\n",
    "Description: A set of learnable filters.\n",
    "Rationale: Chose to set 32 filters for the first two Conv2D layers and 64 filters for the last two. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN can isolate features that are useful everywhere from these transformed images (feature maps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxPool2D: Acts as a \"downsampling\" filter. It looks at the the 2 neighbroing pixes and picks the maximal value. These are used to reduce computational cost and to some extent also reduce overfiting.  We have to choose the pooling size ((i.e. the area size polled each time). The higher the pooling dimesion, the more downsampling is important.\n",
    "\n",
    "Downsampling is a process applied to digital signals which reduces the amplitude of certain features, is my best guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their weights to zero) for each training sample. This drops randomly a proportion of the network and forces the network to learn features in a distributed way.  This technique also improves generalization and reduces the overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'relu' is the rectifier (activation function max(0,x).) The rectifier acitivation function is used to add non-linearity to the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flatten layer is used to convert the final feature maps into a single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This user used the features in two fully-connected (Dense) layers which is just Artifical an Neural Networks (ANN) classifier.  In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model\n",
    "# my CNN architecture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten \n",
    "# -> Dense -> Dropout -> Out]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',\n",
    "                            activation = 'relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same',\n",
    "                               activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',\n",
    "                               activation = 'relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',\n",
    "                              activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up a score function, a loss function, and an optimisation algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function to measure how poorly our model performs with known labels.  It is the error rate between the observed labels and the predicted ones.  This user uses a specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important function is the optimizer. This function will iteratively improve parameter (filters kernel values, weights and bias of neurons...) in order to minimize the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This user chose RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSProp.\n",
    "\n",
    "The metric function \"\"accuracy\" is used to evaluate the performance of our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay =0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complie the model\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the optimizer converge faster and closest to the global minimum of the loss function, he used an annealing method of the learning rate (LR).\n",
    "\n",
    "The LR is the step by which the optimizer walks through the 'loss landscape'. The higher the LR, the bigger the steps and the quicker is the convergence. However, the sampling is very poor with a high LR and the optimizer could probably fall into a local minima.\n",
    "\n",
    "Its better to have a decreasing learning rate during the traiing to reach efficiently the global minimum of the loss function.\n",
    "\n",
    "To keep the advantage of the fast computation time with a high LR, he decreased the LR dynamically every X steps (epochs) depending on if it is necessary (when accuracy is not improved).\n",
    "\n",
    "With the ReduceLROnPlateau function from Keras.callbacks, I choose to reduce the LR by half if the accuracy is not imporvoed after 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                            patience = 3,\n",
    "                                            verbose = 1,\n",
    "                                            factor = 0.5,\n",
    "                                            min_lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30 # Turn to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ordre to avoid overfitting, we need to expand artificially the handwritten digit data set. We can make the existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations occuring when someone is writing a digit.\n",
    "\n",
    "For example, the number is not centered, the scale is not the same (some write with big/small numbers), the image is rotated...\n",
    "\n",
    "Approaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and many more.\n",
    "\n",
    "By applying just a couple of these transformations to out training data, we can easily double or triple the number of training examples and create a very robust model.\n",
    "\n",
    "The improvement is important:\n",
    "˚Without data augmentation accuracy is 98.114%\n",
    "˚With, 99.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation he obtained an accuracy of 0.98114\n",
    "#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs,\n",
    "#                    validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, #set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  #set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  #divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,    #divide each input by its std\n",
    "        zca_whitening=False,       #apply ZCA whitening\n",
    "        rotation_range=10,        # randomly rotate images in the range (degrees, 0 to 100)\n",
    "        zoom_range = 0.1,          # randomly zoom\n",
    "        width_shift_range=0.1,     # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,    # randomly shift images vertically (fraction of total width)\n",
    "        horizontal_flip=False,    # randomly flip images\n",
    "        vertical_flip=False)      # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data augmentation:\n",
    " Randomly rotate by 10˚, zoom by 10%, shift hor/vert by 10%.\n",
    " \n",
    " NO vertical flip or horiz flip since numbers can be symmetrric, and this would cause 69 issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 88s - loss: 0.0696 - accuracy: 0.9786 - val_loss: 0.0477 - val_accuracy: 0.9897\n",
      "Epoch 2/30\n",
      " - 87s - loss: 0.0644 - accuracy: 0.9811 - val_loss: 0.0371 - val_accuracy: 0.9899\n",
      "Epoch 3/30\n",
      " - 86s - loss: 0.0589 - accuracy: 0.9822 - val_loss: 0.0363 - val_accuracy: 0.9913\n",
      "Epoch 4/30\n",
      " - 86s - loss: 0.0612 - accuracy: 0.9825 - val_loss: 0.0382 - val_accuracy: 0.9910\n",
      "Epoch 5/30\n",
      " - 86s - loss: 0.0591 - accuracy: 0.9826 - val_loss: 0.0398 - val_accuracy: 0.9915\n",
      "Epoch 6/30\n",
      " - 96s - loss: 0.0581 - accuracy: 0.9827 - val_loss: 0.0419 - val_accuracy: 0.9907\n",
      "Epoch 7/30\n",
      " - 93s - loss: 0.0535 - accuracy: 0.9850 - val_loss: 0.0408 - val_accuracy: 0.9902\n",
      "Epoch 8/30\n",
      " - 91s - loss: 0.0563 - accuracy: 0.9847 - val_loss: 0.0491 - val_accuracy: 0.9905\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/30\n",
      " - 93s - loss: 0.0426 - accuracy: 0.9876 - val_loss: 0.0377 - val_accuracy: 0.9921\n",
      "Epoch 10/30\n",
      " - 96s - loss: 0.0439 - accuracy: 0.9872 - val_loss: 0.0413 - val_accuracy: 0.9905\n",
      "Epoch 11/30\n",
      " - 90s - loss: 0.0397 - accuracy: 0.9883 - val_loss: 0.0468 - val_accuracy: 0.9907\n",
      "Epoch 12/30\n",
      " - 89s - loss: 0.0426 - accuracy: 0.9879 - val_loss: 0.0366 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/30\n",
      " - 89s - loss: 0.0347 - accuracy: 0.9896 - val_loss: 0.0351 - val_accuracy: 0.9921\n",
      "Epoch 14/30\n",
      " - 89s - loss: 0.0370 - accuracy: 0.9899 - val_loss: 0.0384 - val_accuracy: 0.9915\n",
      "Epoch 15/30\n",
      " - 89s - loss: 0.0351 - accuracy: 0.9898 - val_loss: 0.0384 - val_accuracy: 0.9915\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/30\n",
      " - 89s - loss: 0.0316 - accuracy: 0.9910 - val_loss: 0.0353 - val_accuracy: 0.9918\n",
      "Epoch 17/30\n",
      " - 89s - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.0371 - val_accuracy: 0.9921\n",
      "Epoch 18/30\n",
      " - 89s - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.0370 - val_accuracy: 0.9926\n",
      "Epoch 19/30\n",
      " - 89s - loss: 0.0319 - accuracy: 0.9911 - val_loss: 0.0408 - val_accuracy: 0.9918\n",
      "Epoch 20/30\n",
      " - 89s - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.0386 - val_accuracy: 0.9915\n",
      "Epoch 21/30\n",
      " - 90s - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.0377 - val_accuracy: 0.9918\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 22/30\n",
      " - 89s - loss: 0.0288 - accuracy: 0.9916 - val_loss: 0.0366 - val_accuracy: 0.9918\n",
      "Epoch 23/30\n",
      " - 88s - loss: 0.0285 - accuracy: 0.9921 - val_loss: 0.0361 - val_accuracy: 0.9921\n",
      "Epoch 24/30\n",
      " - 89s - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.0344 - val_accuracy: 0.9929\n",
      "Epoch 25/30\n",
      " - 89s - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.0382 - val_accuracy: 0.9921\n",
      "Epoch 26/30\n",
      " - 89s - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.0359 - val_accuracy: 0.9929\n",
      "Epoch 27/30\n",
      " - 89s - loss: 0.0282 - accuracy: 0.9920 - val_loss: 0.0374 - val_accuracy: 0.9923\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 28/30\n",
      " - 90s - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.0353 - val_accuracy: 0.9913\n",
      "Epoch 29/30\n",
      " - 93s - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0370 - val_accuracy: 0.9921\n",
      "Epoch 30/30\n",
      " - 93s - loss: 0.0260 - accuracy: 0.9924 - val_loss: 0.0383 - val_accuracy: 0.9921\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size = batch_size),\n",
    "                             epochs = epochs, validation_data = (X_val, Y_val),\n",
    "                             verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                             callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label='Training Loss')\n",
    "ax[0].plot(history.history['val_loss'], color='r', label='validation loss', axes =ax[0])\n",
    "legen = ax[0].legend(loc='best', shadow = True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r', label=\"Validation accuracy\")\n",
    "legen = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "#select the index with the maximum probability\n",
    "results = np.argmax(results, axis=1)\n",
    "\n",
    "results = pd.Series(results, name='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name=\"ImageId\"),results],axis=1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datgen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
